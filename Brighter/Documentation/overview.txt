Command Processors
Introduction
------------
In this article, we are going to talk about requirements for a commmand processor implementation. We will then discuss the API of our implementation ,and show the usage of that implementation. A later article will look at the details of the implementation.

Why?
----
We want to use a ports and adapters architectural style. http://alistair.cockburn.us/Hexagonal+architecture

A ports & adapters architectural style (Hexagonal Architecture) is a variation of the n-tier architectural style which makes clear the seperation between the domain model - which contains the rules of our application - and the adapters, which abstract the inputs to the system and our outputs. The advantage of this style is that the application is decoupled from the nature of the input or output device, and any frameworks used to implement them. 

For example when a client POSTs a request to the REST API exposed by our application the adapter recieves the HTTP request, transforms it into a call onto our domain, and marshals the response back out to the client over HTTP. Similarly if our application needs to retrieve persisted entity state to initialise the domain it calls out to an adapter that wraps access to the Db.

The layer between the adapter and the domain is identified as the Ports layer. Our domain is inside the port, adapters for external entities are on the outisde of the port. The notion of a 'port' invokes the OS idea that any device that adheres to a know protocol can be plugged into a port. Similarly, many adapters may use our ports.

One particular asset is testability. Our tests can be written agains the ports, instead of the adapters. This decouples our tests from the adapters - which may change over time as we add or remove external entities we wish to use to surface the application. It also means that our functionality must be contained inside the port, against which the test runs, and cannot bleed into other layers. A traditional problem of n-tier architectures is bleeding of domain logic out of the domain and into the presentation layer. The ports and adapters model seeks to solve this, by forcing adapters to use the API exposed by the port. Writing TDD unit tests at this layer means that the test driven-development pushes the domain logic required to implement behind the port.

$See figure hexagonal_architecture.vsd
$See figure hexagonal_architecture.vsd

We have a notion of primary and secondary actors in use cases which map to the adapter and port layer. Primary actors exercise our application, they are inputs into our application. A primary actor uses a primary adapter, which calls a primary port - the chain is one of inputs into our application. So our REST API is a primary adapter, so are our tests. A secondary actor is one that our application exercises as part of its work, they are outputs from out application. So our Db is a secondary adapter, as our mocks and we talk to them over a secondary port. Many applications seem to consist only of one primary and one secondary, which leads to the n-tier style, but once we factor in tests we may begin to observe that we have more, and by building for multiple ports we make our application more modifiable to new ports in future.

We often show primary ports on the left and secondary ports on the right.

A port is the 'use case boundary'. Use cases become problematic when they become focused on technology concerns. Use cases written against the ports can elide those concerns and focus on the application rules, making them easier to write and maintain. There is a correlation here between the use case boundary and the test boundary - tests should focus on the behaviour expressed by a use case, not on a unit of code. Contrary to Cockburn, we don't suggest using a ATT like FIT or SpecFlow here, preferring to use our xUnit test tool here (and not test implementation details). 

How to implement the API at the Port?
------------------------------------

One question is, how is our API provided? We are inside an adapter, so we might want to use a Plain Old C# Object (POCO) approach to avoid framework dependencies. A common route is to use the Facade pattern, providing a class that holds the API to lower level components. Indeed this is the classical implementation strategy for the application service layer in an layered architecture. The Facade design pattern provides a high-level interface to a sub-system, shielding the caller from the implementation details of the sub-system. This both reduces complexity for the caller, and decouples the caller from the implementation allowing us to vary it without amending the caller. To this extent it meets the needs of our port, providing a clear notion of outside - the caller and inside - the subsystem. 

A Facade used in this context is being used in the Service role, where the Service stereotype describes an object that provides co-ordination and control logic.

<code>
public class MyFatService
{
    public void CreateMyThing(/* .. parameters ...*/)
    {
        /*Stuff*/
    }

    public void UpdateMyThingForFoo(/* .. parameters ...*/)
    {
       /*Other Stuff*/
    }

     public void UpdateMyThingForBar(/* .. parameters ...*/)
     {
        /*Other Stuff*/
     }

     /*Loads more of these*/
}
<code/>

The Interface Segregation Principle states that clients should not be forced to depend on methods on an interface that they do not use. This is because we do not want to update the client because the interface changes to service other clients in a way that the client itself does not care about. An Operation Script style domain service classes force consumers (for example MVC controllers) to become dependent on methods on the domain service class that they do not consume.

Now this can be obviated by having the domain service implement a number of interfaces, and hand to its clients interfaces that only cover the concerns they have. With application service layers this naturally tends towards one method per interface.

<code>
public interface ICreateMyThingService
{
    void CreateMyThing(/* .. parameters ...*/);
}

public interface IUpdateMyThingForFooService
{
    void UpdateMyThingForFoo(/* .. parameters ...*/);
}

public interface IUpdateMyThingForBarService
{
   void UpdateMyThingForBar(/* .. parameters ...*/);
}

public class MyFatService : ICreateMyThingService, IUpdateMyThingForFooService, IUpdateMyThingForBarService
{
   public void CreateMyThing(/* .. parameters ...*/)
  {
      /*Stuff*/
   }

   public void UpdateMyThingForFoo(/* .. parameters ...*/)
  {
      /*Other Stuff*/
  }

   public void UpdateMyThingForBar(/* .. parameters ...*/)
   {
      /*Other Stuff*/
    }

/*Loads more of these*/

}
<code/>

Now the Single Responsibility Principle suggests that a class should have one and only one reason to change. All these separate interfaces begin to suggest that a separate class might be better for each interface, to avoid updating a class for concerns that it does not have. So we tend to move toward one class per API endpoint.

public interface ICreateMyThingService
{
    void CreateMyThing(/* .. parameters ...*/);
}

public class CreateMyThingService : ICreateMyThingService
{
    public void CreateMyThing(/* .. parameters ...*/)
    {
       /*Stuff */
    }
}

public interface IUpdateMyThingForFooService
{
    void UpdateMyThingForFoo(/* .. parameters ...*/);
}

public class UpdateMyThingForFooService : IUpdateMyThingForBarService
{
    public void UpdateMyThingForBar(/* .. parameters ...*/)
   {
      /*Other Stuff*/
   }
}

public interface IUpdateMyThingForFooService
{
   void UpdateMyThingForBar(/* .. parameters ...*/);
}

public class UpdateMyThingForFooService : IUpdateMyThingForFooService
{
   public void UpdateMyThingForFoo(/* .. parameters ...*/)
  {
    /*Other Stuff*/
  }
}

We may begin to realize that we are implementing something that resembles the Command design pattern.

Command Design Pattern
----------------------
The command design pattern encapsulates a request as an object, allowing reuse, queueing or logging of requests, or undoable operations. It also serves to decouple the implementation of the request from the requestor. The caller of a command object does not need to understand how the command is actioned, only that the command exists. When the caller and the implementer are decoupled it becomes easy to replace or refactor the implementation of the request, without impacting the caller - our system is more modifiable. Our ability to test the command in isolation of the caller - allows us to implement the ports and adapters model easily - we can instantiate the command, provide 'fake' parameters to it and confirm the results. We can also use the command from multiple callers, although this is not a differentiator from the service class approach.

In addition we can structure a system transactionally using commands. A command is essentially a transactional boundary. Because a command is a transactional boundary, when using the Domain Driven Development technique of an aggregate there is a natural affinity between the command, which operates on a transactional boundary and the aggregate which is a transactional boundary within the domain model. The aggregate is the Reciever stereotype within the Command Design pattern. Because we want to seperate use of outgoing adapters via a secondary port, such as a Repository in the DDD case, this can lead to a pattern for implementaton of a command:

1: Begin Transaction
2: Load from Repository
3: Operate on Aggregate
4: Flush to Repository
5: Commit Transaction

In Domain Driven Design we may need to notify other aggregates that can be eventually consistent of the change within the transactionally consistent boundary. The pattern suggested there is to raise a domain event. Because the handling of that domain event is in itself likely to be a transactional boundary for a different aggregate we can encapsulate this domain event with the Command design pattern as well, which gives rise to the following additional step to the sequence, outside the original transactional boundary:

6: Invoke Command Encapsulating Domain Event

Implementing the pattern is simple, we implement a command interface, that has a method to execute the command. We then create a concrete instance of the command that derives from this interface. The invoking class executes the command without being directly coupled to the reciever which the command uses to implement the action requested.

A Macro command is a command that consists of other commands. At its simplest form this is just a class that contains a list of commands to execute in sequence. A Macro Command has no Receiver, because each Command in the list has its own Receiver 

<code>
public interface IAmACommand
{
		void Execute();
}
<code/>

$See figure Command Sequence diagram


From our perspective, the single method API endpoints are in fact commands. We could rewrite

<code>
public class UpdateMyThingForFooinService : IUpdateMyThingForFooinService
{
   public void UpdateMyThingForFoo(/* .. parameters ...*/)
  {
    /*Other Stuff*/
  }
}
<code/>

using an interface to represent a command as

<code>
public interface IAmACommand
{
		void Execute();
}

public class UpdateMyThingForFooFooCommand 
{
	public UpdateMyThingForFooCommand(/* .. parameters ...*/)
	{
		/* Initialize state of command for members */
	}

  public void Execute()
  {
    /*Other Stuff*/
  }
}

<code/>

So we could implement our ports in our hexagonal architecure as a collection of commands. Those commands form the API for our application, and they can be called from primary actors such as tests or a REST API. In turn those command may use an outbound secondary port, as discussed in the discussion of the Command and Aggregate patterns above. 

Implementation Example - Hystrix
--------------------------------
https://github.com/Netflix/Hystrix

Command Processor Pattern
-------------------------
The Command design pattern encapsulates request, and decouples the caller from the implementation details of the request. The pattern description discusses the opportunity that commands give to manage a sequence of requests (for example providing support for undo) or support orthogonal operations such as logging, but gives few details on how to do that. The Command Processor pattern provides details of how to manage a set of commands used to seperate the request for service from its execution. The Command Processor accepts requests for Commands, schedules and executes them, manages their history (such as storing for later undo or replay) and performs any other orthogonal housekeeping operations. The client is decoupled from the responsibilities of managing and scheduling commands.

A Command Processor enforces quality of service and maximizes throughput.

The command processor provides the primary port in our ports and adapters model, because it provides the API which can be used to drive the domain model

A command processor can also be used with a Message instead of a Command. Because the responsibility for executing a Command lies with the Command Processor not with the Client, we do not necessarily wish to expose that operation to the Client. Instead we can use a Message - in this case a flat data structure that potentially has both header and body - and have the Command Processor find the Command that it needs to execute in order to service the request represented by the Message.

The Command Processor needs to map the Message to a Command. One option is to use the Intepreter to parse the Message and route it - this can be as simple as using reflection on the Command type and finding an associated Command.


Timeout and Circuit Breaker
---------------------------
When dealing with a distributed application we want to avoid the failure of one component causing the failure of other components - a chain failure. For example if we need to access a resource across the network such as a database, a webservice or REST API, a network file share is not available, then we will find that requests that access those resources will fail. However, they may fail slowly, as our application waits for the connection to respond. This ties up a thread waiting for that resource to respond. In a multi-threaded web server, requests are serviced from a thread pool. If a thread 

If there is no timeout then 

Interpreter
-------------
POSA Vol 4 Chapter 18
"When designing a Command Processor (343) that receives request messages, or a Command (412) or Component Configurator (490) that receives script-based configuration parameters, or—more generally— a parameterizable Encapsulated Implementation (313) . . .

. . . a mechanism is needed to interpret the data or scripts and execute the right services on the component.

Some problems are often resolved via interpretation rather than by precompiled algorithms. For example, searching for strings that match a particular pattern can be resolved by interpreting regular expressions. Interpreting an input stream or a data model in a little domain-specific language, however, requires grammar representation and an implementation of execution semantics."

Command Dispatcher
------------------
http://doanduyhai.wordpress.com/2012/08/04/design-pattern-the-asynchronous-dispatcher/
http://my.safaribooksonline.com/9780132964937/ch12lev1sec3

Reengineering >NET Chapter 12
The basic idea is to have a set of classes called Commands, each of which is self-contained and able to perform a specific function. These commands are registered with the command dispatcher service along with a specific condition that the command is capable of handling. During run-time, the business logic submits the parameters describing a certain condition that is possibly unpredictable at design time, and the dispatcher determines which one or more of the commands to execute.
http://weblogs.asp.net/shijuvarghese/archive/2011/10/18/cqrs-commands-command-handlers-and-command-dispatcher.aspx
http://hillside.net/plop/plop2001/accepted_submissions/PLoP2001/bdupireandebfernandez0/PLoP2001_bdupireandebfernandez0_1.pdf

---> Related patterns diagram. Do a related patterns diagram with Command Processor at the center and then pushing out to all the other patterns we use as part of the solution

Implementation Details - MFC
----------------------------
http://www.microsoft.com/msj/0795/dilascia/dilascia.aspx

CanRoute? We should add this to our Command Processor

> Command Dispatcher is not about orthogonal services with commands, but mapping message to command (I'd say it's a variation implicit in using the message version of command processor, but...)
> Pipeline is one way to do the orthogonal services
 
Pipes and Filters
-----------------
POSA vol 4, chapter 9
"A Pipes and Filters architecture decouples different data processing steps so that they can evolve independently of one another and support an incremental data processing approach.

Within a Pipes and Filters architecture, filters are the units of domain-specific computation. Each filter can be implemented as a Domain Object (208) that represents a specific, self-contained data processing step. Filters with a concurrent Domain Object implementation enable incremental and concurrent data processing, which increases the performance and throughput of a Pipes and Filters arrangement. If a filter performs a long-duration activity, consider integrating multiple parallel instances of the filter into the processing chain. Such a configuration can further increase system performance and throughput, as some filter instances can start processing new data streams while others are processing previous data streams.

Pipes are the medium of data exchange and coordination within a Pipes and Filters architecture. Each pipe is a Domain Object that implements a policy for buffering and passing data along the filter chain: data producing filters write data into a pipe, while data consuming filters receive their input from a pipe. The integration of pipes decouples adjacent filters so that the filters can operate independently of one another, which maximizes their individual operational performance.

In a single-process Pipes and Filters arrangement, pipes are typically implemented as queues. Pipes with a concurrent Domain Object implementation enable incremental and concurrent data processing, as do concurrent filters. In a distributed arrangement, pipes are realized as some form of Messaging (221) infrastructure that passes data streams between remote filters. Pipes that are implemented as a Domain Object shield filters from a knowledge of their specific implementation, which also allows transparent swapping of implementation forms. Such a design supports a flexible (re-)deployment of filters in a distributed Pipes and Filters arrangement. Messages (420) help to encapsulate the data streams that are passed along the pipes."

>We should talk about Interceptors as an alternative
Interceptor



Decouple - Chain of Responsibility
Extend - Decorators



